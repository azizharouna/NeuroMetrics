{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelization \n",
    "For this analysis, let's consider a range of regression models:\n",
    "\n",
    "* Linear Regression: A simple baseline model.\n",
    "* Ridge Regression: Linear regression with L2 regularization.\n",
    "* Lasso Regression: Linear regression with L1 regularization.\n",
    "* Random Forest Regressor: A decision tree-based ensemble method.\n",
    "* Gradient Boosting Regressor: Boosting-based ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utilspro.py\n",
    "execute_notebook(\"3_data_preprocessing.ipynb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': 96.72539177942704,\n",
       " 'Ridge Regression': 96.80781600694735,\n",
       " 'Lasso Regression': 97.24170054684595,\n",
       " 'Random Forest Regressor': 99.14816629889401,\n",
       " 'Gradient Boosting Regressor': 85.90483782690822}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Create pipelines for each model\n",
    "pipelines = {name: Pipeline([('model', model)]) for name, model in models.items()}\n",
    "\n",
    "# Train and evaluate each pipeline\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Train the model\n",
    "    pipeline.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    predictions = pipeline.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute the mean squared error\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    results[name] = mse\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient Boosting Regressor has the lowest MSE, making it the best-performing model among the ones we evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's focus on hyperparameter tuning for the best-performing model, which is the Gradient Boosting Regressor\n",
    "\n",
    "* n_estimators: The number of boosting stages to be run.\n",
    "* learning_rate: Determines the contribution of each tree to the final prediction.\n",
    "* max_depth: The maximum depth of the individual regression estimators.\n",
    "* min_samples_split: The minimum number of samples required to split an internal node.\n",
    "* min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "\n",
    "We will define a grid for these hyperparameters and perform a grid search to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for Gradient Boosting Regressor\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object for Gradient Boosting Regressor\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "best_params, best_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
